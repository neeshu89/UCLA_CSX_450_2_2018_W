{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Central Limit Theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = pd.read_csv('Wholesale_customers_data.csv')\n",
    "customers.Region = customers.Region.astype('category')\n",
    "customers.Channel = customers.Channel.astype('category')\n",
    "customer_features = customers.select_dtypes(int)\n",
    "\n",
    "display(customers.info())\n",
    "display(customers.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='review-statistics-parameters'></a>\n",
    "\n",
    "### Review: Sample Statistics and Parameters\n",
    "\n",
    "---\n",
    "\n",
    "Recall that we use sample statistics to estimate population parameters. Our goal is to calculate sample statistics and then rely on properties of a random sample (and perhaps additional assumptions) to make inferences that we can generalize to the larger population of interest.\n",
    "\n",
    "Below is a table comparing some example sample statistics and population parameters:\n",
    "\n",
    "Metric  | Statistic  | Parameter \n",
    "-------- | ---------- | -------- \n",
    "mean   | $$\\bar{x} = \\frac{\\sum x}{n}$$ | $$ \\mu = \\frac{\\sum x}{N} $$      \n",
    "standard deviation   | $$ s = \\sqrt{\\frac{\\sum_i (x_i - \\bar{x})^2}{n-1}} $$ | $$ \\sigma = \\sqrt{\\frac{\\sum_i (x_i - \\mu)^2}{N} } $$\n",
    "correlation   | $$ r = \\frac{\\hat{Cov}(X, Y)}{s_X s_Y} $$ | $$ \\rho = \\frac{Cov(X, Y)}{\\sigma_X \\sigma_Y} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Normal Distribution\n",
    "\n",
    "---\n",
    "\n",
    "The normal distribution is arguably the most commonly used distribution in all of statistics. **Normality** is an assumption that underlies many statistical tests and serves as a convenient model for the distribution of many (but not all!) variables.\n",
    "\n",
    "The normal distribution relies on two parameters: \n",
    "- The population mean\n",
    "- The population standard deviation \n",
    "\n",
    "If a variable follows a Normal distribution exactly, its mean, median, and mode will all be equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,5))\n",
    "\n",
    "for i in range(1,5):\n",
    "    yy = np.random.normal(size=10**i)\n",
    "    fig.add_subplot(1,4,i)\n",
    "    sns.distplot(yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='zdist-rule'></a>\n",
    "\n",
    "### The 68-95-99.7 Rule\n",
    "\n",
    "---\n",
    "\n",
    "It is often beneficial to identify how extreme (or far away from the expected value) a particular observation is within the context of a distribution. \n",
    "\n",
    "It is possible to show that, for a Normal distribution:\n",
    "- 68% of observations from a population will fall within $\\pm 1$ standard deviation of the population mean.\n",
    "- 95% of observations from a population will fall within $\\pm 2$ standard deviations of the population mean.\n",
    "- 99.7% of observations from a population will fall within $\\pm 3$ standard deviations of the population mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('titanic.csv')\n",
    "titanic_age = titanic.Age.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(titanic_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_age_mean = titanic_age.mean()\n",
    "titanic_age_std = titanic_age.std()\n",
    "titanic_age_mean, titanic_age_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What percentage of passengers have an age between 15 and 45?\n",
    "\n",
    "What percentage of passengers have an age above 30?\n",
    "\n",
    "What percentage of passengers have an age between 15 and 60?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below is a visual representation of the 68-95-99.7 rule on the IQ distribution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(titanic_age)\n",
    "plt.axvline(titanic_age_mean, color='black', lw=3)\n",
    "plt.axvline(titanic_age_mean - titanic_age_std, color='black', lw=2, ls=\"dashed\")\n",
    "plt.axvline(titanic_age_mean + titanic_age_std, color='black', lw=2, ls=\"dashed\")\n",
    "plt.axvline(titanic_age_mean - 2*titanic_age_std, color='black', lw=1, ls=\"dashed\")\n",
    "plt.axvline(titanic_age_mean + 2*titanic_age_std, color='black', lw=1, ls=\"dashed\")\n",
    "plt.axvline(titanic_age_mean - 3*titanic_age_std, color='black', lw=.5, ls=\"dashed\")\n",
    "plt.axvline(titanic_age_mean + 3*titanic_age_std, color='black', lw=.5, ls=\"dashed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The z-score\n",
    "\n",
    "\n",
    "The z-score of an observation quantifies how many standard deviations the observation is away from the population mean:\n",
    "\n",
    "### $$ z_i = \\frac{x_i - \\text{population mean of x}}{\\text{standard deviation of x}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_feature_z_scores = (customer_features - customer_features.mean())/customer_features.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = customer_feature_z_scores.sample(4)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.plot(kind='bar', figsize=(20,5))\n",
    "labels = [\"Sample {}\".format(i) for i in sample.index]\n",
    "plt.xticks(range(samples_cpy.shape[0]+2),labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central Limit Theorem\n",
    "\n",
    "---\n",
    "\n",
    "Normality underlies many of the inferential techniques that we use in data science.\n",
    "\n",
    "Consider the random variable $X$. We can take a sample from this population of size $n$ and find the mean of that sample. Let's call this sample mean $x_1$. We can take another sample from this population, also of size $n$, and find the mean of that sample. Let's call this sample mean $x_1$. We can do this over and over until we've calculated the mean of every possible sample of size $n$. If we plotted every sample mean on a histogram, we get another distribution called \"the sampling distribution of $\\bar{X}$.\"\n",
    "\n",
    "**This distribution, the sampling distribution of $\\bar{X}$, is Normally distributed even if the distribution of $X$ is not.** (That is, unless some rare conditions are violated).\n",
    "\n",
    "We can formally define [the central limit theorm](http://homepages.math.uic.edu/~bpower6/stat101/Sampling%20Distributions.pdf) like so:\n",
    "\n",
    "> In probability theory, the central limit theorem states that, when independent random variables are added, their sum tends toward a normal distribution (commonly known as a bell curve), even if the original variables themselves are not normally distributed. In more precise terms, given certain conditions, the arithmetic mean of a sufficiently large number of iterates of independent random variables — each with a well-defined (finite) expected value and finite variance — will be approximately normally distributed, regardless of the underlying distribution.\n",
    "\n",
    "Some properties that arise from the central limit theorem include:\n",
    "\n",
    "> If $X ~ N(\\mu,\\sigma)$, then $\\bar{X}$ is exactly $N(\\mu,\\frac{\\sigma}{\\sqrt{n}})$\n",
    "\n",
    "> If $X$ is not normally distributed, then $\\bar{X}$ is approximately $N(\\mu,\\frac{\\sigma}{\\sqrt{n}})$ if the sample size $n$ is at least 30. As $n$ increases, $\\bar{X}$ becomes asymptotically normally distributed.\n",
    "\n",
    "> If $\\bar{X}$ is normally distributed, then we can use inferential methods that rely on our sample mean, $\\bar{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='additional-resources'></a>\n",
    "\n",
    "### Additional resources\n",
    "\n",
    "---\n",
    "\n",
    "http://blog.vctr.me/posts/central-limit-theorem.html\n",
    "\n",
    "http://www.usablestats.com/lessons/central_limit\n",
    "\n",
    "http://blog.minitab.com/blog/michelle-paret/explaining-the-central-limit-theorem-with-bunnies-and-dragons-v2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
